{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pandas as pd  # Import pandas for reading CSV\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Simulate time series data\n",
    "seq_length = 16000  # Update sequence length\n",
    "input_size = 6  # Update input size\n",
    "output_size = 1\n",
    "\n",
    "# Generate example data\n",
    "# Replace this with loading your data from a CSV\n",
    "df = pd.read_csv('Daily_RMSE.csv')\n",
    "column_names = ['Doy', 'GPT2w_ZTD', 'Daily_RMSE']\n",
    "Input = df[column_names]\n",
    "Output = df['GAMIT_ZTD']\n",
    "data = np.array(Input)\n",
    "target = np.array(Output)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "data_tensor = torch.FloatTensor(data)\n",
    "target_tensor = torch.FloatTensor(target)\n",
    "\n",
    "# Move data and model to GPU (if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "data_tensor = data_tensor.to(device)\n",
    "target_tensor = target_tensor.to(device)\n",
    "\n",
    "# Define a Transformer model\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_size, d_model, output_size):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.transformer = nn.Transformer(d_model, nhead=2, num_encoder_layers=2)\n",
    "        self.fc = nn.Linear(input_size, d_model)\n",
    "        self.output = nn.Linear(d_model, output_size)\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src = self.fc(src)\n",
    "        tgt = self.fc(tgt)\n",
    "        out = self.transformer(src, tgt)\n",
    "        out = self.output(out)\n",
    "        return out\n",
    "\n",
    "# Initialize the model and move it to the GPU\n",
    "d_model = 64  # Transformer's dimension\n",
    "model = TransformerModel(input_size, d_model, output_size).to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Lists to store metrics\n",
    "mae_values = []\n",
    "mse_values = []\n",
    "bias_values = []\n",
    "loss_values = []\n",
    "\n",
    "# Training the model\n",
    "num_epochs = 30\n",
    "for epoch in range(num_epochs):\n",
    "    mae_sum = 0.0\n",
    "    mse_sum = 0.0\n",
    "    bias_sum = 0.0\n",
    "\n",
    "    start_time = time.time()  # Record start time for training\n",
    "\n",
    "    for i in range(seq_length):\n",
    "        inputs = data_tensor[i:i+1]\n",
    "        targets = target_tensor[i:i+1]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs, inputs)  # Use the same input for both src and tgt\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate MAE and MSE\n",
    "        mae = torch.abs(outputs - targets).mean().item()\n",
    "        mse = ((outputs - targets) ** 2).mean().item()\n",
    "\n",
    "        mae_sum += mae\n",
    "        mse_sum += mse\n",
    "\n",
    "        # Calculate bias\n",
    "        bias = (outputs - targets).mean().item()\n",
    "        bias_sum += bias\n",
    "\n",
    "        # Store MAE and MSE at each time step\n",
    "        mae_values.append(mae)\n",
    "        mse_values.append(mse)\n",
    "\n",
    "    end_time = time.time()  # Record end time for training\n",
    "    training_time = end_time - start_time\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Training Time: {training_time:.2f} seconds')\n",
    "\n",
    "    # Calculate average MAE and MSE\n",
    "    average_mae = mae_sum / seq_length\n",
    "    average_mse = mse_sum / seq_length\n",
    "    average_bias = bias_sum / seq_length\n",
    "\n",
    "    loss_values.append(loss.item())\n",
    "\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Average MAE: {average_mae:.4f}, Average MSE: {average_mse:.4f}, Average Bias: {average_bias:.4f}')\n",
    "\n",
    "# Use the model for prediction and calculate MAE, MSE, and bias\n",
    "predicted_outputs = []\n",
    "predicted_mae_sum = 0.0\n",
    "predicted_mse_sum = 0.0\n",
    "predicted_bias_sum = 0.0\n",
    "predicted_mae_concate = []\n",
    "predicted_mse_concate = []\n",
    "\n",
    "start_time = time.time()  # Record start time for inference\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(seq_length):\n",
    "        test_input = data_tensor[i:i+1]\n",
    "        predicted_output = model(test_input, test_input)\n",
    "\n",
    "        # Calculate MAE, MSE, and bias for the predicted outputs\n",
    "        predicted_mae = torch.abs(predicted_output - target_tensor[i:i+1]).mean().item()\n",
    "        predicted_mse = ((predicted_output - target_tensor[i:i+1]) ** 2).mean().item()\n",
    "\n",
    "        predicted_mae_sum += predicted_mae\n",
    "        predicted_mse_sum += predicted_mse\n",
    "        predicted_mae_concate.append(predicted_mae)\n",
    "        predicted_mse_concate.append(predicted_mse)\n",
    "        predicted_bias = (predicted_output - target_tensor[i:i+1]).mean().item()\n",
    "        predicted_bias_sum += predicted_bias\n",
    "\n",
    "end_time = time.time()  # Record end time for inference\n",
    "inference_time = end_time - start_time\n",
    "\n",
    "# Calculate\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from autorank import autorank, plot_stats, create_report, latex_table\n",
    "\n",
    "np.random.seed(42)\n",
    "pd.set_option('display.max_columns', 7)\n",
    "std = 0.3\n",
    "means = [0.2, 0.3, 0.5, 0.8, 0.85, 0.9]\n",
    "sample_size = 50\n",
    "data = pd.DataFrame()\n",
    "for i, mean in enumerate(means):\n",
    "    data['pop_%i' % i] = np.random.normal(mean, std, sample_size).clip(0, 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv(\"Multi and uni on MSE.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "    Periormer  FEDformer  Autoformer  Informer  LogTrans  Reformer\n0       0.118      0.138       0.095     0.098     0.103     0.222\n1       0.136      0.156       0.144     0.158     0.167     0.284\n2       0.157      0.197       0.182     0.179     0.207     1.522\n3       0.172      0.205       0.186     0.191     0.230     1.860\n4       0.192      0.233       0.205     0.222     0.273     2.122\n..        ...        ...         ...       ...       ...       ...\n75      0.295      0.399       0.421     0.468     0.527     0.563\n76      0.344      0.415       0.437     0.528     0.610     0.694\n77      0.357      0.476       0.483     0.637     0.679     0.740\n78      0.428      0.537       0.614     0.679     0.806     0.893\n79      0.534      0.681       0.724     0.763     0.781     0.926\n\n[80 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Periormer</th>\n      <th>FEDformer</th>\n      <th>Autoformer</th>\n      <th>Informer</th>\n      <th>LogTrans</th>\n      <th>Reformer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.118</td>\n      <td>0.138</td>\n      <td>0.095</td>\n      <td>0.098</td>\n      <td>0.103</td>\n      <td>0.222</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.136</td>\n      <td>0.156</td>\n      <td>0.144</td>\n      <td>0.158</td>\n      <td>0.167</td>\n      <td>0.284</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.157</td>\n      <td>0.197</td>\n      <td>0.182</td>\n      <td>0.179</td>\n      <td>0.207</td>\n      <td>1.522</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.172</td>\n      <td>0.205</td>\n      <td>0.186</td>\n      <td>0.191</td>\n      <td>0.230</td>\n      <td>1.860</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.192</td>\n      <td>0.233</td>\n      <td>0.205</td>\n      <td>0.222</td>\n      <td>0.273</td>\n      <td>2.122</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>75</th>\n      <td>0.295</td>\n      <td>0.399</td>\n      <td>0.421</td>\n      <td>0.468</td>\n      <td>0.527</td>\n      <td>0.563</td>\n    </tr>\n    <tr>\n      <th>76</th>\n      <td>0.344</td>\n      <td>0.415</td>\n      <td>0.437</td>\n      <td>0.528</td>\n      <td>0.610</td>\n      <td>0.694</td>\n    </tr>\n    <tr>\n      <th>77</th>\n      <td>0.357</td>\n      <td>0.476</td>\n      <td>0.483</td>\n      <td>0.637</td>\n      <td>0.679</td>\n      <td>0.740</td>\n    </tr>\n    <tr>\n      <th>78</th>\n      <td>0.428</td>\n      <td>0.537</td>\n      <td>0.614</td>\n      <td>0.679</td>\n      <td>0.806</td>\n      <td>0.893</td>\n    </tr>\n    <tr>\n      <th>79</th>\n      <td>0.534</td>\n      <td>0.681</td>\n      <td>0.724</td>\n      <td>0.763</td>\n      <td>0.781</td>\n      <td>0.926</td>\n    </tr>\n  </tbody>\n</table>\n<p>80 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RankResult(rankdf=\n",
      "            meanrank  median     mad ci_lower ci_upper effect_size   magnitude\n",
      "Periormer    5.88750  0.3505  0.1935    0.192    0.617         0.0  negligible\n",
      "FEDformer    4.33750  0.4370   0.241    0.222    0.714   -0.266964       small\n",
      "Autoformer   4.00000  0.4530  0.2625    0.248    0.732   -0.299812       small\n",
      "Informer     3.32500  0.5175  0.2855    0.313    0.857   -0.461871       small\n",
      "LogTrans     2.25625  0.6235   0.313    0.334    0.877   -0.707663      medium\n",
      "Reformer     1.19375  0.8585   0.458    0.506    1.269   -0.974597       large\n",
      "pvalue=7.092463789123216e-65\n",
      "cd=0.8429434015371722\n",
      "omnibus=friedman\n",
      "posthoc=nemenyi\n",
      "all_normal=False\n",
      "pvals_shapiro=[1.1941232891388154e-08, 3.168653339713501e-09, 7.060440676553981e-09, 3.125241576640292e-08, 1.560624340868344e-08, 0.00011791979341069236]\n",
      "homoscedastic=True\n",
      "pval_homogeneity=0.07397543383869123\n",
      "homogeneity_test=levene\n",
      "alpha=0.05\n",
      "alpha_normality=0.008333333333333333\n",
      "num_samples=80\n",
      "posterior_matrix=\n",
      "None\n",
      "decision_matrix=\n",
      "None\n",
      "rope=None\n",
      "rope_mode=None\n",
      "effect_size=akinshin_gamma)\n"
     ]
    }
   ],
   "source": [
    "result=autorank(data, alpha=0.05, verbose=False)\n",
    "print(result)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The statistical analysis was conducted for 6 populations with 80 paired samples.\n",
      "The family-wise significance level of the tests is alpha=0.050.\n",
      "We rejected the null hypothesis that the population is normal for the populations Periormer (p=0.000), FEDformer (p=0.000), Autoformer (p=0.000), Informer (p=0.000), LogTrans (p=0.000), and Reformer (p=0.000). Therefore, we assume that not all populations are normal.\n",
      "Because we have more than two populations and the populations and some of them are not normal, we use the non-parametric Friedman test as omnibus test to determine if there are any significant differences between the median values of the populations. We use the post-hoc Nemenyi test to infer which differences are significant. We report the median (MD), the median absolute deviation (MAD) and the mean rank (MR) among all populations over the samples. Differences between populations are significant, if the difference of the mean rank is greater than the critical distance CD=0.843 of the Nemenyi test.\n",
      "We reject the null hypothesis (p=0.000) of the Friedman test that there is no difference in the central tendency of the populations Periormer (MD=0.350+-0.212, MAD=0.193, MR=5.888), FEDformer (MD=0.437+-0.246, MAD=0.241, MR=4.338), Autoformer (MD=0.453+-0.242, MAD=0.262, MR=4.000), Informer (MD=0.518+-0.272, MAD=0.286, MR=3.325), LogTrans (MD=0.623+-0.271, MAD=0.313, MR=2.256), and Reformer (MD=0.859+-0.381, MAD=0.458, MR=1.194). Therefore, we assume that there is a statistically significant difference between the median values of the populations.\n",
      "Based on the post-hoc Nemenyi test, we assume that there are no significant differences within the following groups: FEDformer and Autoformer; Autoformer and Informer. All other differences are significant.\n"
     ]
    }
   ],
   "source": [
    "create_report(result)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 600x185 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_stats(result)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[h]\n",
      "\\centering\n",
      "\\begin{tabular}{lrrllll}\n",
      "\\toprule\n",
      "{} &    MR &   MED &   MAD &              CI & $\\gamma$ &   Magnitude \\\\\n",
      "\\midrule\n",
      "Periormer  & 5.888 & 0.350 & 0.193 &  [0.192, 0.617] &     0.000 &  negligible \\\\\n",
      "Fedformer  & 4.338 & 0.437 & 0.241 &  [0.222, 0.714] &    -0.267 &       small \\\\\n",
      "Autoformer & 4.000 & 0.453 & 0.262 &  [0.248, 0.732] &    -0.300 &       small \\\\\n",
      "Informer   & 3.325 & 0.518 & 0.286 &  [0.313, 0.857] &    -0.462 &       small \\\\\n",
      "LogTrans   & 2.256 & 0.623 & 0.313 &  [0.334, 0.877] &    -0.708 &      medium \\\\\n",
      "Reformer   & 1.194 & 0.859 & 0.458 &  [0.506, 1.269] &    -0.975 &       large \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\caption{Summary of populations}\n",
      "\\label{tbl:stat_results}\n",
      "\\end{table}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\77154\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\autorank\\autorank.py:697: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  table_string = table_df.to_latex(float_format=float_format, na_rep='-').strip()\n"
     ]
    }
   ],
   "source": [
    "latex_table(result)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
